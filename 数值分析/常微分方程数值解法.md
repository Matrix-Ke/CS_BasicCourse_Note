#! https://zhuanlan.zhihu.com/p/568552092
# 深入理解欧拉方法

在物理模拟中经常需要求解常微分方程， 欧拉方法以及其变体方法经常被使用。

### 常微分⽅程

#### 初值问题
问题描述：： 
* 常微分方程初值问题是常微分方程理论研究与实际应用中的一种基本定解问题。
* 求解和讨论常微分方程： 
$$
\frac{d y}{d x}=f(x, y) \\
$$
满足初值条件: 
$$
y(x_0)=y_0 \tag{2} \\
$$
的解的问题称为常微分方程初值问题，条件(2)称为初值条件或初始条件
* 初值问题主要讨论的问题有：初值问题是否存在解，解的存在域有多大；解是否惟一

### 核心概念引入

#### 利普希茨（Lipschitz）条件：
* Lipschitz条件，即利普希茨连续条件（Lipschitz continuity）。其定义为：对于函数 $\mathrm{f}(\mathrm{x}, \mathrm{y})$ 满足: $\left|\mathrm{f}\left(\mathrm{x}, \mathrm{y}_1\right)-\mathrm{f}\left(\mathrm{x}, \mathrm{y}_2\right)\right| \leq \mathrm{L}\left|\mathrm{y}_1-\mathrm{y}_2\right|$。
* 大白话就是：存在一个实数L，使得对于函数 $\mathrm{f}(\mathrm{x}, \mathrm{y})$上的每对点，连接它们的线的斜率的绝对值不大于这个实数L。最小的L称为该函数的Lipschitz常数。
* 在微分方程理论中，Lipschitz连续性是Picard-Lindelöf定理的核心条件，它保证了初值问题解的存在性和唯一性。Lipschitz连续条件（Lipschitz continuity）是一个比一致连续更强的光滑性条件。直观上，Lipschitz连续函数限制了函数改变的速度。符合Lipschitz条件的函数，其斜率必小于一个称为Lipschitz常数的实数。

### 问题给出和概念介绍
对于一阶微分方程的初值问题: 若f(x, y)关于x 连续，关于y 满⾜Lipschitz条件, 则：
$$
\left\{\begin{array}{l}
y^{\prime}(x)=f(x, y), \quad x>a \\
y(a)=y_0
\end{array}\right.\\
$$
存在唯⼀解. **在无法(或者无需)给出解析表达式的时候如何利用数值方法求出近似解?**

>Note: 证明如下：
Hint: 假设上述问题的初值为 $z_0$, 则相应的解记为 $z(x)$, 满足
$$
z^{\prime}(x)=f(x, z)
$$
现考察 $z(x)-y(x)$ 的性质; 记
$$
r(x)=z(x)-y(x)
$$
有
$$
\begin{cases}r^{\prime}(x) & =f(x, z)-f(x, y) \\ r(a) & =z(0)-y(0)\end{cases}
$$
或者:
$$
r^{\prime}(x)=\frac{f(x, z)-f(x, y)}{z-y} r(x):=h(x, r) * r(x)\\
$$
记
$$
H(x)=\int_a^x h(x) d x=\int_a^x h(t) d t
$$
改写目标为
$$
r^{\prime}(x) e^{-H(x)}=e^{-H(x)} * h(x) * r(x)
$$
得到
$$
\frac{d}{d x}\left(e^{-H(x)} * r(x)\right)=0 \rightarrow e^{-H(x)} * r(x)=\text { constant }
$$
即
$$
e^{-H(x)} * r(x)=e^{-H(a)} * r(a)=z_0-y_0 \rightarrow r(x)=e^{H(x)} *\left(z_0-y_0\right)
$$
进而
$$
|z(x)-y(x)|=e^{\int_0^x h(t) d t} *\left|z_0-y_0\right| \leq e^{L *(x-a)} *\left|z_0-y_0\right|
$$
所以有： 当满足Lipschitz条件时，存在$z_0$, 对应唯一解 $z(x)$。

#### 何为数值解？
在有限区间 $[a, b]$ 上寻求方程
$$
\left\{\begin{array}{l}
y^{\prime}(x)=f(x, y), \quad x>a \\
y(a)=y_0  \\
\end{array}\right. \\
$$
的 解 $y(x)$ 在一系列点
$$
a=x_0<x_1<x_2<\ldots<x_n=b \\
$$
上的近似值
$$
y_1, y_2, \ldots, y_n \text { 即 } y_k \approx y\left(x_k\right), \quad k=1,2, \ldots, n \text {. } \\
$$
>Note:  
>* 形如上式左端$y_k$的符号为数值解，$y\left(x_k\right)$为精确解 

简单起见, 将区间 $[a, b]\,, \mathrm{N}$ 等分, 记 $h=\frac{b-a}{N}$ 为网格步长, 记
$$
x_k=a+k h, \quad k=0,1,2, \ldots, N
$$
为网格节点. 所谓数值解: 寻找一个网格函数 (只在网格节点处有定义的函数), 也即是一 个向量 $\left\{y_k\right\}_{k=1}^N$, 使得
$$
y_k \approx y\left(x_k\right), \quad k=1,2, \ldots, N
$$

### 一阶初值求解方法:
**有两种求解方法：**
单步法 : 计算下一个点的值 $y_{n+1}$ 只需要用到前面一个点的值 $y_n$。
* Euler 法，梯形法，Runge-Kutta法
  
多步法 ：计算下一个点的值 $y_{n+1}$ 需要用到前面 $l$ 个点的值 $y_l$
*  Adams method 。。、

#### Euler解法：
网格节点 $\quad a=x_0<x_1<\ldots<x_N=b, \quad x_{j+1}-x_j=h=\frac{b-a}{N}$ 方程 $y^{\prime}=f(x, y), \quad a<x<b$
设 $y(x) \in C^2[a, b]$, 由Taylor expansion
$$
\begin{aligned}
y\left(x_{k+1}\right) &=y\left(x_k\right)+y^{\prime}\left(x_k\right) h+\frac{h^2}{2} y^{\prime \prime}(\xi) \\
&=y\left(x_k\right)+f\left(x_k, y\left(x_k\right)\right) h+ \frac{h^2}{2} y^{\prime \prime}\left(\xi_k\right) \\
\end{aligned}\\
$$

##### 向前Euler⽅法
上述得泰勒表达式，去掉$\frac{h^2}{2} y^{\prime \prime}\left(\xi_k\right)$,可得： 
$$
\left\{\begin{array}{l}
y_{k+1}=y_k+h f\left(x_k, y_k\right), \\
y_0=y(a) \text { 初值已知 }
\end{array} \quad k=0,1,2, \ldots\right.
$$
求解上式即得到网格函数 (向量) $\left[y_0, y_1, y_2, \ldots, y_N\right]^{\mathrm{T}}$

**思考：** 
所得向量是否为有效近似？精度如何？如何量化这些误差关系。

example： $\left\{\begin{array}{l}y^{\prime}=y-\frac{2 x}{y} \quad 0<x<1 \\ y(0)=1\end{array}\right.$
通过数值计算发现，对于fowrad Euler： 
* 误差随⾃变量增长⽽变⼤
* 步长缩⼩，误差减⼩

##### Euler⽅法的误差估计(收敛性)
$$
\begin{aligned}
y\left(x_{k+1}\right) &=y\left(x_k\right)+y^{\prime}\left(x_k\right) h+\frac{h^2}{2} y^{\prime \prime}(\xi)=y\left(x_k\right)+f\left(x_k, y\left(x_k\right)\right) h+\frac{h^2}{2} y^{\prime \prime}\left(\xi_k\right) \\
y_{k+1} &=y_k+h f\left(x_k, y_k\right)
\end{aligned}
$$
记 $\varepsilon_k=y\left(x_k\right)-y_k$, 得到误差方程
$$
\varepsilon_{k+1}=\varepsilon_k+h \varepsilon_k F_k+\frac{h^2}{2} y^{\prime \prime}\left(\xi_k\right) \qquad (F_k=\frac{f\left(x_k, y\left(x_k\right)\right)-f\left(x_k, y_k\right)}{y\left(x_k\right)-y_k}) \\
$$
进而得到:
$$
\begin{aligned}
\left|\varepsilon_{k+1}\right| \leq &(1+h L)\left|\varepsilon_k\right|+\frac{1}{2}\left\|y^{\prime \prime}\right\|_{\infty} h^2:=A\left|\varepsilon_k\right|+\underset{\sim}{B} \\
& \leq A\left(A\left|\varepsilon_{k-1}\right|+B\right)+B \\
& \leq A^2\left|\varepsilon_{k-1}\right|+(1+A) B \leq A^{k+1}\left|\varepsilon_0\right|+\left(1+A+\ldots+A^k\right) B \\
&=A^{k+1} * \varepsilon_0+\frac{A^{k+1}-1}{A-1} B \leq C(L, y, b-a) * h\\
&=\left(e^{(b-a) L} * \frac{\left\|y^{\prime \prime}\right\|_{\infty}}{2 L}\right) * h \\
\end{aligned}\\
$$
所以可以知道Euler方法得总体误差估计为：$\left(e^{(b-a) L} * \frac{\left\|y^{\prime \prime}\right\|_{\infty}}{2 L}\right) * h$

#### Euler⽅法的一般稳定性 (0稳定， Lax-stable)
假设给定Euler格式两个不同初值 $z_0, y_0$, 若 $\left|\varepsilon_0\right|=\left|z_0-y_0\right|$ 比较小, $\varepsilon_k=z_k-y_k$ 是否也比较小?
$$
\begin{aligned}
&z_{k+1}=z_k+h f\left(x_k, z_k\right) \\
&y_{k+1}=y_k+h f\left(x_k, y_k\right)
\end{aligned}
$$
两式相减得到扰动方程： 
$$
\left\{\begin{array}{l}
\varepsilon_{k+1}=\varepsilon_k+h \varepsilon_k F_k \\
\varepsilon_0=z_0-y_0 \\
\end{array}\right.  \qquad (F_k=\frac{f\left(x_k, z_k\right)-f\left(x_k, y_k\right)}{z_k-y_k})\\
$$
进⽽得到:
$$
\begin{aligned}
\left|\varepsilon_{k+1}\right| & \leq (1+h L)\left|\varepsilon_k\right|+ \| y^{\prime \prime}\|_{\infty} h^2:=A\left|\varepsilon_k\right|+ B \\
& \leq A\left(A\left|\varepsilon_{k-1}\right|+B\right)+B \\
&=A^{k+1} * \varepsilon_0+\frac{A^{k+1}-1}{A-1} B \leq e^{(b-a) L} |\varepsilon_0|
\end{aligned}
$$
从上式可以知道：
* $(a-b)$ 越小，误差越小了, 即有区间越小，误差变慢慢变小, 即该方法时**稳定的**。
* $L$ Lipschitz越大，即函数越陡，误差会变大。

##### 局部截断误差(Local Truncation Error) LTE
**教材定义：**

Euler格式 $y_{k+1}=y_k+h * f\left(x_k, y_k\right)$ 的LTE：
$$
T_{k+1}=y\left(x_{k+1}\right)-\left[y\left(x_k\right)+h * f\left(x_k, y\left(x_k\right)\right)\right]
$$
Euler格式(规范化 normalized) $\frac{y_{k+1}-y_k}{h}=f\left(x_k, y_k\right)$ 的Normalized - LTE： 
$$
\tau_{k+1}=\frac{y\left(x_{k+1}\right)-y\left(x_k\right)}{h}-f\left(x_k, y\left(x_k\right)\right)
$$
>Note: 
> * 两种定义⽅式仅仅是定义或者记号，不影响数值计算和误差估计！ 后者与PDE的LTE定义⼀致！！
> * 局部截断误差 LTE 一般可以使用 Taylor展开推导出来。（通用方法）

**精度&格式：**
精度：
* 若数值格式的局部截断误差满足$T=\boldsymbol{O}\left(h^{p+1}\right)$ 则称之为 $p$ 阶格式
* 如果上述LET采用规范化的定义方式, 则 $\tau=\boldsymbol{O}\left(h^p\right) \rightarrow$ p阶精度 !

相容性：当h越小时，截断误差越小。
$$
\tau \rightarrow y^{\prime}-f(x, y) \quad \text { as } \quad h \rightarrow 0 \\
$$

####  Euler 方法的改进

#### 梯形⽅法
在区间 $\left[x_j, x_{j+1}\right]$ 上积分得到:
$$
\int_{x_j}^{x_{j+1}} y^{\prime}(x) d x=\int_{x_j}^{x_{j+1}} f(x, y) d x
$$
左端可以Newton-Leibniz 写出, 右端采用数值积分公式（其中  $\frac{h^3}{12} y^{\prime \prime}\left(\xi_j\right)$ 是梯形公式的误差）
$$
y\left(x_{j+1}\right)-y\left(x_j\right)=\frac{h}{2}\left[f\left(x_j, y\left(x_j\right)\right)+f\left(x_{j+1}, y\left(x_{j+1}\right)\right)\right]+\frac{h^3}{12} y^{\prime \prime}\left(\xi_j\right) \\
$$
丢掉小量项得梯形方法:
$$
y_{j+1}=y_j+\frac{h}{2}\left[f\left(x_j, y_j\right)+f\left(x_{j+1}, y_{j+1}\right)\right]
$$
Newton 法、割线法、二分法 都可以用于计算。更为常用的简单迭代算法如下:
$$
\left\{\begin{array}{l}
y_{j+1}^{(0)}=y_j \quad \text { OR } \quad y_j+h f\left(x_j, y_j\right) \\
y_{j+1}^{(k+1)}=y_j+\frac{h}{2}\left[f\left(x_j, y_j\right)+f\left(x_{j+1}, y_{j+1}^{(k)}\right)\right], \quad k=1,2,3, \ldots \\
\end{array}\right. \\
$$
#### backward Euler
左端可以Newton-Leibniz 写出, 右端采用右矩形公式
$$
y\left(x_{j+1}\right)-y\left(x_j\right)=h * f\left(x_{j+1}, y\left(x_{j+1}\right)\right)+\frac{h^2}{2} y^{\prime \prime}\left(\xi_j\right)
$$
丢掉小量项得 backward Euler method
$$
y_{j+1}=y_j+h * f\left(x_{j+1}, y_{j+1}\right) \\
$$
Newton 法、割线法、或者简单迭代算法均可⽤于求解上述⾮线性⽅程组
$$
\left\{\begin{array}{l}
y_{j+1}^{(0)}=y_j \\
y_{j+1}^{(k+1)}=y_j+h * f\left(x_{j+1}, y_{j+1}^{(k)}\right), \quad k=1,2,3, \ldots \\
\end{array}\right. \\
$$

#### 改进的Euler法算法实现
改进的Euler公式: 
* 梯形公式不好求解在于$y_{j+1}$不好求，那么将其拆解成两步走。
* 计算出预测值$y_{\text {pred }}$ ， 将$y_{j+1} = y_{\text {pred }}$ 。
$$
\left\{\begin{array}{l}
y_{\text {pred }}=y_j+h * f\left(x_j, y_j\right) \\
y_{j+1}=y_j+\frac{h}{2}\left[f\left(x_j, y_j\right)+f\left(x_{j+1}, y_{\text {pred }}\right)\right] \\
\end{array}\right. \\
$$
改进的Euler也是预测-校正, 也是 2 阶 Runge-Kutta ; 编程时按照如下方式进行
$$
\left\{\begin{array}{l}
K_1=f\left(x_j, y_j\right) \\
K_2=f\left(x_{j+1}, y_j+h * K_1\right) \\
y_{j+1}=y_j+h \frac{K_1+K_2}{2}
\end{array}\right.
$$
由微分中值定理: 
$$
y_{(j+1)}=y_{(j)}+h * y^{\prime}\left(\xi_j\right)  \\
$$

#### Runge−Kutta解法：
思想：改进的Euler方法的延申。

**经典四阶Runge-Kutta⽅法： RK4**
$$
\left\{\begin{array}{l}
K_1=f\left(x_k, y_k\right) \\
K_2=f\left(x_k+\frac{h}{2}, y_k+\frac{h}{2} K_1\right) \\
K_3=f\left(x_k+\frac{h}{2}, y_k+\frac{h}{2} K_2\right) \\
K_4=f\left(x_k+h, y_k+h K_3\right) \\
y_{k+1}=y_k+\frac{h}{6}\left(K_1+2 K_2+2 K_3+K_4\right) \\
\end{array}\right. \\
$$



### 